{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JEN6YT/APS360/blob/main/Jennifer_Lab5_Spam_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bphECiUa9zw"
      },
      "source": [
        "# Lab 5: Spam Detection\n",
        "\n",
        "In this assignment, we will build a recurrent neural network to classify a SMS text message\n",
        "as \"spam\" or \"not spam\". In the process, you will\n",
        "    \n",
        "1. Clean and process text data for machine learning.\n",
        "2. Understand and implement a character-level recurrent neural network.\n",
        "3. Use torchtext to build recurrent neural network models.\n",
        "4. Understand batching for a recurrent neural network, and use torchtext to implement RNN batching.\n",
        "\n",
        "### What to submit\n",
        "\n",
        "Submit a PDF file containing all your code, outputs, and write-up. You can produce a PDF of your Google Colab file by going to File > Print and then save as PDF. The Colab instructions have more information.\n",
        "\n",
        "Do not submit any other files produced by your code.\n",
        "\n",
        "Include a link to your colab file in your submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWiUqJJTa9z6"
      },
      "source": [
        "## Colab Link\n",
        "\n",
        "Include a link to your Colab file here. If you would like the TA to look at your\n",
        "Colab file in case your solutions are cut off, **please make sure that your Colab\n",
        "file is publicly accessible at the time of submission**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wbu28XcNKah"
      },
      "source": [
        "Colab Link: https://colab.research.google.com/drive/1VZjl01M7BIukPKH6WvQtHl6OCnrq3Axi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvcBGmjHNKah"
      },
      "source": [
        "As we are using the older version of the torchtext, please run the following to downgrade the torchtext version:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSK7yPPBNKai"
      },
      "source": [
        "!pip install -U torch==1.8.0+cu111 torchtext==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcNM3rE2NKai"
      },
      "source": [
        "If you are interested to use the most recent version if torchtext, you can look at the following document to see how to convert the legacy version to the new version:\n",
        "https://colab.research.google.com/github/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTKKXEX8KusL",
        "outputId": "c555973e-745d-4e4e-c1b1-52d93470d649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp39-cp39-linux_x86_64.whl (1982.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m821.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp39-cp39-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0+cu111) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0+cu111) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.9.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.8.0+cu111 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0+cu111 torchtext-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torch==1.8.0+cu111 torchtext==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HgfNOUaPa9z8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0jLI9LBa90C"
      },
      "source": [
        "## Part 1. Data Cleaning [15 pt]\n",
        "\n",
        "We will be using the \"SMS Spam Collection Data Set\" available at http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
        "\n",
        "There is a link to download the \"Data Folder\" at the very top of the webpage. Download the zip file, unzip it, and upload the file `SMSSpamCollection` to Colab.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSuF7C_Ga90E"
      },
      "source": [
        "### Part (a) [2 pt]\n",
        "\n",
        "Open up the file in Python, and print out one example of a spam SMS, and one example of a non-spam SMS.\n",
        "\n",
        "What is the label value for a spam message, and what is the label value for a non-spam message?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_IfXHeTa90F",
        "outputId": "a6f2d543-11cd-49ae-8b13-fbe132cc4902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "\n",
            "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for line in open('SMSSpamCollection'):\n",
        "  if line[0] == 'h':\n",
        "    print(line)\n",
        "    break\n",
        "\n",
        "for line in open('SMSSpamCollection'):\n",
        "  if line[0] == 's':\n",
        "    print(line)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvSmYsJ_bri8"
      },
      "outputs": [],
      "source": [
        "# the label value for spam is \"spam\" and the label value for a non-spam is \"ham\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AukA6vMVa90d"
      },
      "source": [
        "### Part (b) [1 pt]\n",
        "\n",
        "How many spam messages are there in the data set?\n",
        "How many non-spam messages are there in the data set?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgsqyemVa90e",
        "outputId": "956d169c-f97f-40f5-ff41-c08aee16a1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the number of spam messages is 747 and the number of non-spam messages is 4827\n"
          ]
        }
      ],
      "source": [
        "count_nonspam = 0\n",
        "count_spam = 0\n",
        "for line in open('SMSSpamCollection'):\n",
        "  if line[0] == 'h':\n",
        "    count_nonspam += 1\n",
        "  else:\n",
        "    count_spam += 1\n",
        "  \n",
        "print(\"the number of spam messages is\", count_spam, \"and the number of non-spam messages is\", count_nonspam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1WXxVt6a90h"
      },
      "source": [
        "### Part (c) [4 pt]\n",
        "\n",
        "We will be using the package `torchtext` to load, process, and batch the data.\n",
        "A tutorial to torchtext is available below. This tutorial uses the same\n",
        "Sentiment140 data set that we explored during lecture.\n",
        "\n",
        "https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8\n",
        "\n",
        "Unlike what we did during lecture, we will be building a **character level RNN**.\n",
        "That is, we will treat each **character** as a token in our sequence,\n",
        "rather than each **word**.\n",
        "\n",
        "Identify two advantage and two disadvantage of modelling SMS text\n",
        "messages as a sequence of characters rather than a sequence of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Mhnz8Nk-a90i"
      },
      "outputs": [],
      "source": [
        "# the advantages of modelling the messages as a sequence of characters are:\n",
        "# first, it there are far fewer characters than words in English language, so the total memory for storing\n",
        "# the tokens will be less and thus less memory requirement.\n",
        "# second, the chance of seeing an unknown word is much higher than seeing an unknown character, \n",
        "# so the model is able to generalize better by learning characters\n",
        "\n",
        "# the disadvantages of modelling the messages as a sequence of characters are:\n",
        "# first, it takes more time and more compute to train the model since there is more characters than words\n",
        "# in a sentence. \n",
        "# second, since the meaning of the sentences depend on the relationship between words, if we are only \n",
        "# focusing on each single character, it is harder to extract meaningful relationship in the sentences, or grasp \n",
        "# a better understanding of the whole sentence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie_D0bv9a90k"
      },
      "source": [
        "### Part (d) [1 pt]\n",
        "\n",
        "We will be loading our data set using `torchtext.data.TabularDataset`. The\n",
        "constructor will read directly from the `SMSSpamCollection` file. \n",
        "\n",
        "For the data file to be read successfuly, we\n",
        "need to specify the **fields** (columns) in the file. \n",
        "In our case, the dataset has two fields: \n",
        "\n",
        "- a text field containing the sms messages,\n",
        "- a label field which will be converted into a binary label.\n",
        "\n",
        "Split the dataset into `train`, `valid`, and `test`. Use a 60-20-20 split.\n",
        "You may find this torchtext API page helpful:\n",
        "https://torchtext.readthedocs.io/en/latest/data.html#dataset\n",
        "\n",
        "Hint: There is a `Dataset` method that can perform the random split for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6KQE6dhkho2E"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "\n",
        "text_field = torchtext.legacy.data.Field(sequential=True,      # text sequence\n",
        "                                  tokenize=lambda x: x, # because are building a character-RNN\n",
        "                                  include_lengths=True, # to track the length of sequences, for batching\n",
        "                                  batch_first=True,\n",
        "                                  use_vocab=True)       # to turn each character into an integer index\n",
        "label_field = torchtext.legacy.data.Field(sequential=False,    # not a sequence\n",
        "                                   use_vocab=False,     # don't need to track vocabulary\n",
        "                                   is_target=True,      \n",
        "                                   batch_first=True,\n",
        "                                   preprocessing=lambda x: int(x == 'spam')) # convert text to 0 and 1\n",
        "\n",
        "fields = [('label', label_field), ('sms', text_field)]\n",
        "dataset = torchtext.legacy.data.TabularDataset(\"SMSSpamCollection\", # name of the file\n",
        "                                        \"tsv\",               # fields are separated by a tab\n",
        "                                        fields)\n",
        "\n",
        "train, valid, test = dataset.split(split_ratio=[0.6,0.2,0.2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6nP0Ks_a90o"
      },
      "source": [
        "### Part (e) [2 pt]\n",
        "\n",
        "You saw in part (b) that there are many more non-spam messages than spam messages.\n",
        "This **imbalance** in our training data will be problematic for training.\n",
        "We can fix this disparity by duplicating spam messages in the training set,\n",
        "so that the training set is roughly **balanced**.\n",
        "\n",
        "Explain why having a balanced training set is helpful for training our neural network.\n",
        "\n",
        "Note: if you are not sure, try removing the below code and train your mode."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# having a balanced training set is helpful because given a test example, there is an equal probability of outputting\n",
        "# any of the classes. in order to achieve high accuracy, the network has to learn how to identify each class, and\n",
        "# thus it becomes more robust. for example, the network will learn to classify both spam and non-spam messages. \n",
        "# for an imbalanced training set, it is much probable that the output will likely be the class which appears the most\n",
        "# in the training dataset. for example, the network in our example can just achieve very high accuracy by outputting \n",
        "# 'non-spam' no matter what the input is."
      ],
      "metadata": {
        "id": "_6zWCYzMGMKD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FWvx9_rka90p"
      },
      "outputs": [],
      "source": [
        "# save the original training examples\n",
        "old_train_examples = train.examples\n",
        "# get all the spam messages in `train`\n",
        "train_spam = []\n",
        "for item in train.examples:\n",
        "    if item.label == 1:\n",
        "        train_spam.append(item)\n",
        "# duplicate each spam message 6 more times\n",
        "train.examples = old_train_examples + train_spam * 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7eUmBEva90r"
      },
      "source": [
        "### Part (f) [1 pt]\n",
        "\n",
        "We need to build the vocabulary on the training data by running the below code.\n",
        "This finds all the possible character tokens in the training set.\n",
        "\n",
        "Explain what the variables `text_field.vocab.stoi` and `text_field.vocab.itos` represent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8CQM8flKa90s",
        "outputId": "87933c22-4f92-49d1-cd36-d44d1cacfdf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fc8bf39b580>>, {'<unk>': 0, '<pad>': 1, ' ': 2, 'e': 3, 'o': 4, 't': 5, 'a': 6, 'n': 7, 'r': 8, 'i': 9, 's': 10, 'l': 11, 'u': 12, '0': 13, 'h': 14, 'd': 15, '.': 16, 'm': 17, 'c': 18, 'y': 19, 'w': 20, 'p': 21, 'g': 22, '1': 23, 'f': 24, 'b': 25, '2': 26, 'T': 27, '8': 28, 'k': 29, 'E': 30, 'v': 31, 'S': 32, '5': 33, 'C': 34, 'I': 35, 'O': 36, '4': 37, 'N': 38, 'x': 39, 'A': 40, '6': 41, '7': 42, '3': 43, 'R': 44, ',': 45, '!': 46, '9': 47, 'P': 48, 'W': 49, 'M': 50, 'U': 51, 'L': 52, 'H': 53, 'D': 54, 'G': 55, 'F': 56, 'B': 57, 'Y': 58, '?': 59, \"'\": 60, '/': 61, '£': 62, '&': 63, '-': 64, ':': 65, 'z': 66, 'X': 67, 'V': 68, '*': 69, 'K': 70, 'j': 71, ')': 72, 'J': 73, '+': 74, ';': 75, '(': 76, 'q': 77, 'Q': 78, '#': 79, '\"': 80, '@': 81, '=': 82, 'ü': 83, '>': 84, 'Z': 85, 'Ü': 86, '\\x92': 87, '$': 88, '%': 89, '_': 90, '‘': 91, '|': 92, '¡': 93, '“': 94, '[': 95, ']': 96, '–': 97, '\\x93': 98, '…': 99, '\\x94': 100, '\\\\': 101, '~': 102, '\\t': 103, '\\n': 104, '\\x96': 105, '^': 106, 'ì': 107, '┾': 108, '〨': 109, '鈥': 110})\n",
            "['<unk>', '<pad>', ' ', 'e', 'o', 't', 'a', 'n', 'r', 'i', 's', 'l', 'u', '0', 'h', 'd', '.', 'm', 'c', 'y', 'w', 'p', 'g', '1', 'f', 'b', '2', 'T', '8', 'k', 'E', 'v', 'S', '5', 'C', 'I', 'O', '4', 'N', 'x', 'A', '6', '7', '3', 'R', ',', '!', '9', 'P', 'W', 'M', 'U', 'L', 'H', 'D', 'G', 'F', 'B', 'Y', '?', \"'\", '/', '£', '&', '-', ':', 'z', 'X', 'V', '*', 'K', 'j', ')', 'J', '+', ';', '(', 'q', 'Q', '#', '\"', '@', '=', 'ü', '>', 'Z', 'Ü', '\\x92', '$', '%', '_', '‘', '|', '¡', '“', '[', ']', '–', '\\x93', '…', '\\x94', '\\\\', '~', '\\t', '\\n', '\\x96', '^', 'ì', '┾', '〨', '鈥']\n"
          ]
        }
      ],
      "source": [
        "text_field.build_vocab(train)\n",
        "# text_field.vocab.stoi: it a dictionary that maps all the characters to an integer identifier that represents\n",
        "# the character\n",
        "print(text_field.vocab.stoi) \n",
        "# text_field.vocab.itos: it is a list that documents all the characters appeared in the list of tokens in the order\n",
        "# of their respective integer identifier\n",
        "print(text_field.vocab.itos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC8WVE8Ua90u"
      },
      "source": [
        "### Part (g) [2 pt]\n",
        "\n",
        "The tokens `<unk>` and `<pad>` were not in our SMS text messages.\n",
        "What do these two values represent?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_4Er7KUa90v"
      },
      "outputs": [],
      "source": [
        "# <unk> means unknown, and it represents a word that does not appear in the dictionary\n",
        "# <pad> is a token that increase the size of SMS messages so all the messages in a batch have the same length "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff5CNk7Qa90y"
      },
      "source": [
        "### Part (h) [2 pt]\n",
        "\n",
        "Since text sequences are of variable length, `torchtext` provides a `BucketIterator` data loader,\n",
        "which batches similar length sequences together. The iterator also provides functionalities to\n",
        "pad sequences automatically.\n",
        "\n",
        "Take a look at 10 batches in `train_iter`. What is the maximum length of the\n",
        "input sequence in each batch? How many `<pad>` tokens are used in each of the 10\n",
        "batches?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "V8N8qLWOa90y"
      },
      "outputs": [],
      "source": [
        "train_iter = torchtext.legacy.data.BucketIterator(train,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "Qwz-rOaha902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e841797-956b-443b-8848-697b20092ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[69, 32, 158, 157, 202, 41, 108, 17, 137, 112]\n",
            "[14, 38, 23, 0, 599, 31, 56, 189, 28, 53]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "padcount = 0\n",
        "maxlength = 0\n",
        "length = []\n",
        "pad = []\n",
        "\n",
        "# print(batch.sms[0])\n",
        "# print(batch.label)\n",
        "\n",
        "for batch in train_iter:\n",
        "  if i<10:\n",
        "    for sms in batch.sms[0]:\n",
        "      if len(sms) > maxlength:\n",
        "        maxlength = len(sms)\n",
        "      for token in sms:\n",
        "        if token == text_field.vocab.stoi['<pad>']:\n",
        "          padcount+=1\n",
        "    length.append(maxlength)\n",
        "    maxlength = 0\n",
        "    pad.append(padcount)\n",
        "    padcount = 0\n",
        "    i += 1\n",
        "\n",
        "print(length)  \n",
        "print(pad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7HnqP6_a904"
      },
      "source": [
        "## Part 2. Model Building [8 pt]\n",
        "\n",
        "Build a recurrent neural network model, using an architecture of your choosing. \n",
        "Use the one-hot embedding of each character as input to your recurrent network.\n",
        "Use one or more fully-connected layers to make the prediction based on your\n",
        "recurrent network output.\n",
        "\n",
        "Instead of using the RNN output value for the final token, another often used\n",
        "strategy is to max-pool over the entire output array. That is, instead of calling\n",
        "something like:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(out[:, -1, :])\n",
        "```\n",
        "\n",
        "where `self.rnn` is an `nn.RNN`, `nn.GRU`, or `nn.LSTM` module, and `self.fc` is a \n",
        "fully-connected \n",
        "layer, we use:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(torch.max(out, dim=1)[0])\n",
        "```\n",
        "\n",
        "This works reasonably in practice. An even better alternative is to concatenate the\n",
        "max-pooling and average-pooling of the RNN outputs:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "out = torch.cat([torch.max(out, dim=1)[0], \n",
        "                 torch.mean(out, dim=1)], dim=1)\n",
        "self.fc(out)\n",
        "```\n",
        "\n",
        "We encourage you to try out all these options. The way you pool the RNN outputs\n",
        "is one of the \"hyperparameters\" that you can choose to tune later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "jHl1p_Wwa905",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81bec9a7-9cf9-43c5-eefe-796af40beaca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "# You might find this code helpful for obtaining\n",
        "# PyTorch one-hot vectors.\n",
        "\n",
        "ident = torch.eye(10)\n",
        "print(ident[0]) # one-hot vector\n",
        "print(ident[1]) # one-hot vector\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "print(ident[x]) # one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "4LTQ7zFka909"
      },
      "outputs": [],
      "source": [
        "class rnn(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, n_layers=1):\n",
        "    super(rnn, self).__init__()\n",
        "\n",
        "    # identity matrix for generating one-hot vectors\n",
        "    self.ident = torch.eye(input_size)\n",
        "\n",
        "    # recurrent neural network\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, n_layers, batch_first=True)\n",
        "\n",
        "    # a fully-connected layer that classifies the input into SPAM/HAM\n",
        "    self.fc = nn.Linear(hidden_size, 2) \n",
        "\n",
        "  def forward(self, x):\n",
        "    one_hot = []\n",
        "    for sms in x:\n",
        "      one_hot.append(self.ident[sms])   # generate one-hot vectors of input\n",
        "\n",
        "    input = torch.stack(one_hot)\n",
        "    \n",
        "    output, _ = self.rnn(input)           # get the next output and hidden state\n",
        "    out =  torch.max(output, dim=1)[0]    # max pooling the GRU output\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKIYPl_Ba90_"
      },
      "source": [
        "## Part 3. Training [16 pt]\n",
        "\n",
        "### Part (a) [4 pt]\n",
        "\n",
        "Complete the `get_accuracy` function, which will compute the\n",
        "accuracy (rate) of your model across a dataset (e.g. validation set).\n",
        "You may modify `torchtext.data.BucketIterator` to make your computation\n",
        "faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "pvNfhGD6a91A"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, data):\n",
        "    \"\"\" Compute the accuracy of the `model` across a dataset `data`\n",
        "    \n",
        "    Example usage:\n",
        "    \n",
        "    >>> model = MyRNN() # to be defined\n",
        "    >>> get_accuracy(model, valid) # the variable `valid` is from above\n",
        "    \"\"\"\n",
        "    correct, total = 0, 0\n",
        "    for sms, labels in data:\n",
        "        output = model(sms[0])\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += labels.shape[0]\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlxlcAC1a91C"
      },
      "source": [
        "### Part (b) [4 pt]\n",
        "\n",
        "Train your model. Plot the training curve of your final model. \n",
        "Your training curve should have the training/validation loss and\n",
        "accuracy plotted periodically.\n",
        "\n",
        "Note: Not all of your batches will have the same batch size.\n",
        "In particular, if your training set does not divide evenly by\n",
        "your batch size, there will be a batch that is smaller than\n",
        "the rest. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "CVtf7CJCa91D"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_network(model, train, valid, num_epochs=5, learning_rate=1e-5):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses, train_acc, valid_acc = [], [], []\n",
        "    epochs = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for sms, labels in train:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(sms[0])\n",
        "            loss = criterion(pred, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        losses.append(float(loss))\n",
        "        epochs.append(epoch+1)\n",
        "        train_acc.append(get_accuracy(model, train))\n",
        "        valid_acc.append(get_accuracy(model, valid))\n",
        "        print(\"Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n",
        "              epoch+1, loss, train_acc[-1], valid_acc[-1]))\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(losses, label=\"Train\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Train\")\n",
        "    plt.plot(epochs, valid_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_iter = torchtext.legacy.data.BucketIterator(valid,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "myrnn = rnn(len(text_field.vocab.itos), len(text_field.vocab.itos), n_layers=1)\n",
        "train_network(myrnn, train_iter, valid_iter, num_epochs=4, learning_rate=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "vOEa95E0b4uT",
        "outputId": "59f97f1e-edfc-45d6-cdc0-f7dd25b63ba8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1; Loss 0.666621; Train Acc 0.726000; Val Acc 0.553363\n",
            "Epoch 2; Loss 0.635452; Train Acc 0.943191; Val Acc 0.927354\n",
            "Epoch 3; Loss 0.564454; Train Acc 0.901696; Val Acc 0.958744\n",
            "Epoch 4; Loss 0.182452; Train Acc 0.938910; Val Acc 0.953363\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE3eRkDAa91F"
      },
      "source": [
        "### Part (c) [4 pt]\n",
        "\n",
        "Choose at least 4 hyperparameters to tune. Explain how you tuned the hyperparameters.\n",
        "You don't need to include your training curve for every model you trained.\n",
        "Instead, explain what hyperparemters you tuned, what the best validation accuracy was,\n",
        "and the reasoning behind the hyperparameter decisions you made.\n",
        "\n",
        "For this assignment, you should tune more than just your learning rate and epoch. \n",
        "Choose at least 2 hyperparameters that are unrelated to the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A2GEWfDca91G"
      },
      "outputs": [],
      "source": [
        "# there are a coule of parameters that needs to be tuned. \n",
        "# tuning the number of epoches, learning rate, number of layers in the GRU layer, \n",
        "\n",
        "# First, increase the number of layers in the GRU (to 2) with number of epochs 10\n",
        "# Results: Epoch 10; Loss 0.347943; Train Acc 0.957642; Val Acc 0.953363\n",
        "\n",
        "# The performance was very good, and it didn't appear to overfit the training set since the validation \n",
        "# accuracy was as good (if not better) than the training accuracy for most of the epochs.\n",
        "\n",
        "# Second, a higher learning rate (5e-4)\n",
        "# Results: Epoch 10; Loss 0.375822; Train Acc 0.845; Val Acc 0.8307\n",
        "# it appeared to converge at around 5 epochs and the other 5 epochs past that were overfitting \n",
        "# with just extremely small gains in accuracy. \n",
        "\n",
        "# Third, choosing the number of epoches to be 5 epochs this time.\n",
        "# Results: Epoch 5; Loss 0.314648; Train Acc 0.960598; Val Acc 0.963229\n",
        "# I decided to go with this model since it was just marginally below the numbers of the previous model, \n",
        "# but it was trained significantly less so it's less likely to be overfitted to the training data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7DY56rKa91I"
      },
      "source": [
        "### Part (d) [2 pt]\n",
        "\n",
        "Before we deploy a machine learning model, we usually want to have a better understanding\n",
        "of how our model performs beyond its validation accuracy. An important metric to track is\n",
        "*how well our model performs in certain subsets of the data*.\n",
        "\n",
        "In particular, what is the model's error rate amongst data with negative labels?\n",
        "This is called the **false positive rate**.\n",
        "\n",
        "What about the model's error rate amongst data with positive labels?\n",
        "This is called the **false negative rate**.\n",
        "\n",
        "Report your final model's false positive and false negative rate across the\n",
        "validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "7ggbQSdba91J"
      },
      "outputs": [],
      "source": [
        "# Create a Dataset of only spam validation examples (negative labels)\n",
        "valid_spam = torchtext.legacy.data.Dataset(\n",
        "    [e for e in valid.examples if e.label == 1],\n",
        "    valid.fields)\n",
        "\n",
        "valid_spam_iter = torchtext.legacy.data.BucketIterator(valid_spam,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "# Create a Dataset of only non-spam validation examples (positive labels)\n",
        "valid_nonspam = torchtext.legacy.data.Dataset(\n",
        "    [e for e in valid.examples if e.label == 0],\n",
        "    valid.fields)\n",
        "\n",
        "valid_nonspam_iter = torchtext.legacy.data.BucketIterator(valid_nonspam,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation false negative\n",
        "print(1- get_accuracy(rnn(len(text_field.vocab.itos), len(text_field.vocab.itos), n_layers=2), valid_spam_iter))\n",
        "\n",
        "# validation false positive\n",
        "print(1- get_accuracy(rnn(len(text_field.vocab.itos), len(text_field.vocab.itos), n_layers=2), valid_nonspam_iter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfLJF9zse4aN",
        "outputId": "5ade16de-53f2-41a1-91be-279b0dc27ed4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.004149377593360981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1iRteb3a91O"
      },
      "source": [
        "### Part (e) [2 pt]\n",
        "\n",
        "The impact of a false positive vs a false negative can be drastically different.\n",
        "If our spam detection algorithm was deployed on your phone, what is the impact\n",
        "of a false positive on the phone's user? What is the impact of a false negative?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hFLUOJTGa91Q"
      },
      "outputs": [],
      "source": [
        "# the false positive means that the algorithm detects a spam but there is no spam, so the phone might block \n",
        "# the sender of the message. however, the message might be really important\n",
        "# the false negative means that the algorithm does not detect a spam but there is spam, so the phone use might\n",
        "# receive a spam message, which can be annoying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gznefulsa91V"
      },
      "source": [
        "## Part 4. Evaluation [11 pt]\n",
        "\n",
        "### Part (a) [1 pt]\n",
        "\n",
        "Report the final test accuracy of your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "id": "D5L5D-A1a91W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb3bde7-862b-470a-90bf-cce500b9d833"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8635547576301615"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "test_iter = torchtext.legacy.data.BucketIterator(test,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "get_accuracy(rnn(len(text_field.vocab.itos), len(text_field.vocab.itos), n_layers=2), test_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hjmd8rca91Y"
      },
      "source": [
        "### Part (b) [3 pt]\n",
        "\n",
        "Report the false positive rate and false negative rate of your model across the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "GFiAKztJa91Z"
      },
      "outputs": [],
      "source": [
        "# Create a Dataset of only spam validation examples (negative labels)\n",
        "test_spam = torchtext.legacy.data.Dataset(\n",
        "    [e for e in test.examples if e.label == 1],\n",
        "    test.fields)\n",
        "\n",
        "test_spam_iter = torchtext.legacy.data.BucketIterator(test_spam,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "\n",
        "# Create a Dataset of only non-spam validation examples (positive labels)\n",
        "test_nonspam = torchtext.legacy.data.Dataset(\n",
        "    [e for e in test.examples if e.label == 0],\n",
        "    test.fields)\n",
        "\n",
        "test_nonspam_iter = torchtext.legacy.data.BucketIterator(test_nonspam,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test false negative\n",
        "print(1- get_accuracy(rnn(len(text_field.vocab.itos), len(text_field.vocab.itos), n_layers=2), test_spam_iter))\n",
        "\n",
        "# test false positive\n",
        "print(1- get_accuracy(rnn(len(text_field.vocab.itos), len(text_field.vocab.itos), n_layers=2), test_nonspam_iter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyJK58CHiToq",
        "outputId": "71ee4d12-66e6-444d-ec40-1fa905f55ea7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.36170212765957444\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jGHtQFpa91b"
      },
      "source": [
        "### Part (c) [3 pt]\n",
        "\n",
        "What is your model's prediction of the **probability** that\n",
        "the SMS message \"machine learning is sooo cool!\" is spam?\n",
        "\n",
        "Hint: To begin, use `text_field.vocab.stoi` to look up the index\n",
        "of each character in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "h_2nSJq8a91b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95673e43-6689-4901-95f6-4f902c20f738"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31535351276397705"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "msg = \"machine learning is sooo cool!\"\n",
        "token = []\n",
        "for i in msg:\n",
        "  token.append(torch.tensor(text_field.vocab.stoi[i]))\n",
        "\n",
        "input = torch.stack(token)\n",
        "input.unsqueeze_(0)\n",
        "\n",
        "F.softmax(myrnn(input), dim=1)[0][1].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD1zgYJpa91f"
      },
      "source": [
        "### Part (d) [4 pt]\n",
        "\n",
        "Do you think detecting spam is an easy or difficult task?\n",
        "\n",
        "Since machine learning models are expensive to train and deploy, it is very\n",
        "important to compare our models against baseline models: a simple\n",
        "model that is easy to build and inexpensive to run that we can compare our\n",
        "recurrent neural network model against.\n",
        "\n",
        "Explain how you might build a simple baseline model. This baseline model\n",
        "can be a simple neural network (with very few weights), a hand-written algorithm,\n",
        "or any other strategy that is easy to build and test.\n",
        "\n",
        "**Do not actually build a baseline model. Instead, provide instructions on\n",
        "how to build it.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LTndp-IOa91g"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes spam filtering can be a baseline technique for dealing with spam that can tailor itself \n",
        "# to the email needs of individual users and give low false positive spam detection rates that are generally \n",
        "# acceptable to users.\n",
        "\n",
        "# To build a Naive Bayes classifier\n",
        "# Step 1: Calculate the prior probability for given class labels\n",
        "# Step 2: Find Likelihood probability with each attribute for each class\n",
        "# Step 3: Put these value in Bayes Formula and calculate posterior probability.\n",
        "# Step 4: See which class has a higher probability, given the input belongs to the higher probability class.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}